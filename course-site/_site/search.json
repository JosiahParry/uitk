{
  "articles": [
    {
      "path": "about.html",
      "title": "About the course",
      "author": [],
      "contents": "\nThe past decade has seen the rapid proliferation of large-scale digital data sets, from cell phone records to social media posts, from calls for government services to digitized historical records. With their unprecedented volume and detail, these new resources have opened up a window through which we can closely examine the behavioral and social dynamics of everyday life, and nowhere is this truer than in urban areas, which have the greatest density of both people and technology. This has given rise to urban informatics, and a renewed opportunity to understand the city, its people, and its neighborhoods, and to develop new policies and programs that improve urban life. Big Data for Cities takes an experiential approach that enables students to contribute to this young field. Given unprecedented times, we will apply our newfound skills to the urgent question of the shifting urban landscape in the age of COVID-19.\n\n\n\n",
      "last_modified": "2021-01-25T07:38:33-05:00"
    },
    {
      "path": "city-walk-1.html",
      "title": "City Exploration #1: Tour of a Neighborhood",
      "author": [],
      "contents": "\nSample City Walk Document\nBoston Data Portal Handout\nFor this city exploration assignment, please:\nSelect a neighborhood (or more localized place) based on something notable in the data you are working with this semester, e.g., the highest or lowest value on some variable of interest, a density of cases in one region, etc.\nVisit and explore this neighborhood either in person or virtually, with an eye to the observations you made in the data and how these characteristics manifest themselves in the real world.\nThough there is no strict guideline on how long you need to spend exploring a neighborhood, either in person or virtually, a visit that lasts less than a half-hour would be unlikely to generate enough observations to support a high-quality memo and presentation.\nIn these unorthodox times, you should decide whether you are comfortable visiting an unfamiliar neighborhood in person. It is not obligatory to do so. You can instead use the Boston Data Portal (see the handout attached above and http://worldmap.harvard.edu/boston/) and other online resources, like Google Street, to “visit” the neighborhood virtually. If you choose this option, please make it clear that this was the case in your memo and presentation.\nWrite a 3-5 page memo describing the logic for why you visited this place, what you discovered, and what this tells you about the interpretation of your data. This written document should include images from your walk (or from StreetView if visiting virtually) and maps with data describing the region.\nTo review Sample City Exploration document, see attachments above.\nRubric\nLogic for Exploration: 1 pts.\nExploration: 1.5 pts.\nRe-evaluation of Data: 2 pts.\nDetails (grammar, structure): .5 pts.\n\n\n\n",
      "last_modified": "2021-01-25T07:38:36-05:00"
    },
    {
      "path": "city-walk-2.html",
      "title": "City Exploration #2: Neighborhood through the Lens of Public Media",
      "author": [],
      "contents": "\nSample City Walk Document\nBoston Data Portal Handout\nSelect a neighborhood based on something notable about the measure(s) that you are developing, e.g., the highest or lowest value, an interesting combination of values, etc.\nExplore how this neighborhood is represented and portrayed through news articles, websites, blogs, community organizations, social media, and other online resources. You might also utilize BostonMap to fill out this story with demographic information or StreetView images.\nWrite a 3-5 pg. virtual walk memo describing the logic for why you visited this place, what you discovered, and what this tells you about the interpretation of your data. It will need to include illustrative images from the media you utilized. To review Sample City Exploration document, see attachments above.\nRubric\nLogic for Exploration: 1 pts.\nExploration: 1.5 pts.\nRe-evaluation of Data: 2 pts.\nDetails (grammar, structure): .5 pts.\n\n\n\n",
      "last_modified": "2021-01-25T07:38:36-05:00"
    },
    {
      "path": "city-walk-3.html",
      "title": "City Exploration #3: Urban Hike",
      "author": [],
      "contents": "\nSample City Walk Document\nBoston Data Portal Handout\nThe final City Exploration of the semester will be another in-person “urban hike.” You will “visit” a place or neighborhood, preferably one that is unfamiliar to you, with the goal of again giving further context to your data analyses. You will note that the prompt here is essentially a repeat of the instructions for City Exploration #1, but it will clearly engage with the greater sophistication you have developed over the semester. Also, this City Exploration should incorporate a final reflection on the relevance of your work to local communities and how that has evolved since your first City Exploration.\nSelect a neighborhood based on something notable in your analyses regarding the direction you anticipate for your final project, with an eye towards providing “ground truth” relative to something that has intrigued or challenged you. You might also consider how this particularly “ground truthing” exercise will enable you to evaluate the potential impact or public value of your analyses.\nVisit and explore this neighborhood either in person or through whatever virtual tools you find useful (including Google StreetView, BostonMap, public media, etc.), seeking to observe how the characteristics of the data and your analyses manifest themselves in the real world.\nThough there is no strict guideline on how long you need to spend exploring the neighborhood, a visit that lasts less than a half-hour would be unlikely to generate enough observations to support a high-quality memo and presentation.\nWrite a 3-5 page memo describing the logic for why you visited this place, what you discovered, and what this tells you about the interpretation of your data. This last part should include or be followed by a broader discussion of how your perspective on the relevance of your work for communities has evolved over the course of the semester. This written document should include images from your exploration and maps with data describing the region.\nTo review Sample City Exploration document, see attachments above. These, however, have not historically required the additional reflection included here, so keep that in mind when using them as a model.\nRubric\nLogic for Exploration: 1 pts.\nExploration: 1.5 pts.\nRe-evaluation of Data: 2 pts.\nDetails (grammar, structure): .5 pts.\n\n\n\n",
      "last_modified": "2021-01-25T07:38:38-05:00"
    },
    {
      "path": "final.html",
      "title": "Final Project",
      "author": [],
      "contents": "\nFinal Project Example 1\nFinal Project Example 2\nFinal Project Example 3\nExecutive Director’s Report\nInequities in Navigating a Pandemic\nFinal Assignment: Inform, Measure, and Discover\nThis semester has been composed of three parts, throughout which you have developed skills and undertaken analyses that will converge in your final project. The final project will summarize all of this work in two pieces, the Individual and Group components.\nRubric\nProject: 12%\nPresentation: 8%\nGroup Portion: 5%\nIndividual Component\nThe final paper and presentation will present a research project that reveals one or more discoveries from the data set you have worked with this semester. The project should highlight the measure(s) that you have developed during the semester and incorporate at least one data set in addition to the one you were assigned at the beginning of the course. Note that you are welcome to use any material from the previous midterms and exploratory data assignments for this project.\nThe paper will be in the format of a public report, consisting of:\nA brief Executive Summary that details the main points of your analysis and findings. Think of the audience for this being someone who would benefit from the insights but might not have the time to read the whole paper or the desire to wade through methods.\nAn Introduction that describes the conceptual inspiration for your analysis and why it might be interesting, both conceptually and practically. You might also include hypotheses if appropriate. The Introduction should include a few citations to fully justify and motivate your analyses.\nA brief Data & Methods section that describes the content of your data set, how you calculated any new measures, and other data sources you used. This is not your complete Methods section, but just enough for a reader to be able to understand the content that follows. It should reference the Appendix (see below).\nOne or more Results & Discussion section where you describe your analyses. This might include some basic descriptive statistics (e.g., what is the distribution of a critical measure across the city, what is the average, the max, etc.) and more sophisticated statistical and visual analyses. This part of the paper should strive to tell one or more interesting stories.\nIt does not need to be titled Results & Discussion. In fact, it probably should have one or more subsections with titles that capture precisely what you discovered.\nThis must include either a correlation/regression or a t-test/ANOVA analysis, and at least three visualizations, one of which must be a map.\n\nA Conclusion that briefly interprets what you’ve found and suggests implications for research and policy. This can be about a page and to the point.\nA Methodology Appendix that describes the content of your data set and then summarizes how you calculated any new measures and from where you accessed other measures. Keep in mind that this section should not include detail for detail’s sake, but should provide the information necessary for an expert to (a) fully understand what you did and (b) replicate the work if they so desired.\nPlease use Chicago style for any references. Use in-line citations (as in the scientific papers we have read this semester). Include all references in the references section in alphabetical order and do not include any references not cited in the text.\nThe paper should be 12-15 pgs. of text. There is not a hard minimum for length, but if your paper is shorter than 12 pgs., it is unlikely you fully completed the expectations of the assignment.\nThe presentation that will accompany the paper will likely follow a similar structure, though presentations grant a little more flexibility in style. The Executive Summary will be more a part of your Introduction setting up the talk and there will be no Methodology Appendix, so be mindful of what is necessary for the presentation medium (but be ready for audience questions!). Please keep the presentations to no more than 5 minutes.\nRubric: Paper (Total 12 pts.)\nExecutive Summary: 1.5 pts.\nIntroduction: 1.5 pts.\nData & Methods: .5 pts.\nResults & Discussion: 3 pts.\nConclusion: .5 pts.\nMethodology Appendix: 2 pts.\nVisuals: 1.5 pts.\nDetails: 1.5 pts.\nGroup Component\nAs with the previous two midterms, the group will work together to combine all modifications made by group members into an updated data set and documentation. It will include three parts that will be uploaded to the Dataverse:\nThe record-level file with all new and modified variables included. This is an update of the record-level file submitted for the second midterm.\nAny files at the aggregate level (e.g., census tracts) and the variables describing them. This is an update of the aggregate level file(s) submitted for the second midterm.\nAn updated Data Dictionary that describes the new variables and, if necessary, modifies the description of any already existing variables, as well as variables at the aggregate level of the database. This is an update of the Data Dictionary submitted for the second midterm.\nAnnotated R syntax clearly articulating steps for all data cleaning and variable creation. This should be efficient and complete such that the code could be run all at once on raw data to recreate the updated data set. This is an update of the R Syntax submitted for the second midterm.\nRubric: Group component (Total 5 pts.)\nData: 2 pts.\nSyntax: 2 pts.\nUpdated Documentation: 1 pt.\n\n\n\n",
      "last_modified": "2021-01-25T07:38:39-05:00"
    },
    {
      "path": "index.html",
      "title": "SPPUA 5262: Big Data For Cities",
      "author": [],
      "contents": "\nWelcome\nThis is the supplemental course website for the Spring 2021 offering of SPPUA 5262: Big Data for Cities. I, Josiah Parry, will be your instructor for this asynchronous online offering. I am excited to equip you all with some of the tools needed to analyze the urban commons. While the tools you will learn will be useful, they are by no means the exhaustive list—this is quite impossible!\nThis course is based on Dr. Dan T. O’Brien’s course—the very same that I took a few years ago. I will, however, be making my own adjustments as I see fit and emphasizing the importance of the R programming language and its contemporary packages. A good (and fun) foundation in R is essential to ensuring that you want to continue exploring the urban commons.\nCourse Summary\nThe past decade has seen the rapid proliferation of large-scale digital data sets, from cell phone records to social media posts, from calls for government services to digitized historical records. With their unprecedented volume and detail, these new resources have opened up a window through which we can closely examine the behavioral and social dynamics of everyday life, and nowhere is this truer than in urban areas, which have the greatest density of both people and technology. This has given rise to urban informatics, and a renewed opportunity to understand the city, its people, and its neighborhoods, and to develop new policies and programs that improve urban life. Big Data for Cities takes an experiential approach that enables students to contribute to this young field. Given unprecedented times, we will apply our newfound skills to the urgent question of the shifting urban landscape in the age of COVID-19.\n\n\n\n",
      "last_modified": "2021-01-25T07:38:41-05:00"
    },
    {
      "path": "midterm-1.html",
      "title": "Midterm 1",
      "author": [],
      "contents": "\nThe midterm is composed of two parts: an individual and a group component.\nIndividual Component\nSample README\nREADME Assignment Description\nA README document that acts as a first view into the contents of the data set and how it might be used that should include:\nA brief overview of what the data set contains. This should be a short paragraph composed of short sentences describing the source of the data and the type of information it holds. This will look a lot like the opening paragraph of the Data Dictionary that you have, though possibly even shorter.\n“Fun facts.” Provide about 5-10 pieces of information that are notable and illustrate the nature of the data set. These should be both engaging and potentially useful to someone looking to analyze the data. Taken as a group, they should illustrate multiple ways that the data set might be used (i.e., not all referencing the same variable). For example: “The 311 system categorizes requests for service into 218 types, the most common being General Request.” “The neighborhood with the most 911 calls in 2013 was Dorchester.”\nVisualization. Include at least two visualizations that illustrate some aspect of the data set that you find particularly noteworthy, complementing the “fun facts.”\nKeep it as short as possible. No more than two pages should be necessary (usually). Remember that this is something that a visitor will want to read quickly to decide whether it is of interest.\nTo review a strong example from a previous year, see attachment above.\nGroup Component\nDataverse Guide\nPlease upload an updated version of your data set to the Boston Data Library by the end of the week. Technical instructions for using the Dataverse are attached.\nMake sure your group includes:\nThe record-level file with all new and modified variables included.\nAn updated Data Documentation that describes the new variables and, if necessary, modifies the description of any already existing variables.\nAnnotated R syntax clearly articulating steps for all data cleaning and variable creation. This should be efficient and complete such that the code could be run all at once on raw data to recreate the updated data set.\nLink to Boston Data Library: https://dataverse.harvard.edu/dataverse/BARI\n\n\n\n",
      "last_modified": "2021-01-25T07:38:42-05:00"
    },
    {
      "path": "midterm-2.html",
      "title": "Midterm 2",
      "author": [],
      "contents": "\nThe midterm is composed of two parts: an individual and a group component.\nIndividual Component\nExample Measurement Midterm\nMeasurement Midterm Assignment\nA short paper summarizing the construction of a new aggregate measure and its construction, including:\nA textual description of how the measure was constructed, justifying any specific decisions that were made (for example, categorization of case types). This will include:\nA summary of new variables at the record level (i.e., the original database) that were constructed first as part of the overall calculation of your aggregate measure(s.\nA summary of the new aggregate measure(s) that you’ve calculated and how you have done so.\n\nA short description of the new variable’s distribution and/or values. What’s the mean? Where is it highest? Anything else fun or interesting? Etc. This should include at least one tabular visualization (e.g., histogram) and a map, if appropriate.\nAn appendix with an annotated R syntax articulating all steps required to create the measure(s) (should be your portion of the R syntax copy-and-pasted; see below).\nTo review an strong example from a previous year, see attachment above.\nGroup Component\nBuilding Permits 2018 Documentation\nAn updated version of the data set, loaded into the Dataverse, including:\nThe record-level file with all new and modified variables included. This is an update of the record-level file submitted for the first midterm.\nAny files at the aggregate level (e.g., census tracts) and the variables describing them.\nAn updated Data Dictionary that describes the new variables and, if necessary, modifies the description of any already existing variables, as well as variables at the aggregate level of the database. This is an update of the Data Dictionary submitted for the first midterm. Please see the example posted above for formatting.\nAnnotated R syntax clearly articulating steps for all data cleaning and variable creation. This should be efficient and complete such that the code could be run all at once on raw data to recreate the updated data set. This is an update of the R Syntax submitted for the first midterm.\n\n\n\n",
      "last_modified": "2021-01-25T07:38:44-05:00"
    },
    {
      "path": "syllabus.html",
      "title": "Syllabus",
      "author": [],
      "contents": "\nInstructor: Josiah Parry (j.parry@northeastern.edu)\nAbout me\n\nCourse Meets: Thursdays 15:00-16:00 EST (3pm - 4pm)\nTexts:\nR for Everyone by Jared P. Lander (available as e-book through NU library)\nR for Data Science by Hadley Wickham & Garrett Grolemund\nUrban Informatics Toolkit by Josiah Parry\n\nCourse Mission\nThe past decade has seen the rapid proliferation of large-scale digital data sets, from cell phone records to social media posts, from calls for government services to digitized historical records. With their unprecedented volume and detail, these new resources have opened up a window through which we can closely examine the behavioral and social dynamics of everyday life, and nowhere is this truer than in urban areas, which have the greatest density of both people and technology. This has given rise to urban informatics, and a renewed opportunity to understand the city, its people, and its neighborhoods, and to develop new policies and programs that improve urban life. Big Data for Cities takes an experiential approach that enables students to contribute to this young field. Given unprecedented times, we will apply our newfound skills to the urgent question of the shifting urban landscape in the age of COVID-19.\nCourse Outcomes\nCourse Content\nBig Data for Cities introduces students to the burgeoning field of urban informatics with an eye towards five learning outcomes:\nDescribe the Field of Urban Informatics: Students will read articles and websites that expose them to the researchers, policymakers, practitioners, and companies that are incorporating big data into the study and management of the city, from which they will seek to articulate the themes and connections that constitute the field of urban informatics.\n“Seeing” Neighborhoods through Naturally-Occurring Data: Students will acquire the methods necessary to manage, analyze, and interpret modern digital data (e.g., administrative records) using R statistical software, with a focus on translating data gathered from internet platforms into knowledge that meaningfully describes the dynamics of the city. This experiential aspect of the course is facilitated by the Boston Area Research Initiative (BARI), a center at Northeastern that focuses on urban informatics in the region. The data come from BARI’s efforts to build the Boston Data Portal, which gathers and coordinates data from many sources describing the region; our work will also be informed by the input BARI partners who work in the public, private, and non-profit sectors locally. Data work this semester will focus on data sets that capture the shifting urban landscape in the time of COVID-19.\nSituating Internet Data in their Real-World Context: Naturally-occurring data are a rich source of information about a city, but it is necessary to verify what real-world events they actually describe and how they are meaningful. Students will undertake City Explorations in order to compare the patterns in their data to independent information about neighborhood contexts. They will also discuss their work with various local stakeholders, including public officials and community leaders. These experiences will ground our interpretation of the data while also empowering us to utilize them to support the real communities that they describe.\nCommunicating Discoveries: Analysis is only as useful as the insights that can be derived from it. Students will practice reporting and presenting the results of data analyses both orally and in writing in forms that would be used to communicate to a range of audiences.\nCreating Public Data Products: Students will modify and document improvements they make to the data sets used in the course. These will be stored in BARI’s Boston Data Portal, thereby creating new data products that can be used by others, including our local partners and future classes.\nLearning Dimensions: SAIL\nBig Data for Cities subscribes to Northeastern University’s campus-wide emphasis on experiential learning and does so with a focus on service-learning—that is, applying our newfound technical skills and substantive knowledge to the real-world needs and challenges of local partners. We will do this directly through our analyses of data describing the shifting urban landscape in Boston during COVID-19.\nAs such, the value of the course will be more than just the five content-specific learning outcomes described above; it will also help students to develop general competencies that are useful across contexts. These learning dimensions are captured by the Center for Advancement of Teaching and Learning through Research’s Self-Authored Integrated Learning (SAIL) framework. This course will particularly highlight three of their five dimensions.\nSAIL Dimension\nDefinition\nThis Course\nIntellectual Agility\nLearners develop the ability to use knowledge, behaviors, skills, and experiences flexibly in new and unique situations to innovatively contribute to their field.\nLeverage quantitative thinking for problem solving. Connect data to real-world phenomena. Adjust project goals with new insights.\nSocial Consciousness & Commitment\nLearners develop the confidence, skills, and values to effectively recognize the needs of individuals, communities, and societies and make a commitment to constructively engage in social action.\nIdentify civic challenges. Apply data to better understanding and serving the city. Recognize how to use data to better understand and advocate around problems.\nProfessional & Personal Effectiveness\nLearners develop the confidence, skills, behaviors, and values to effectively discern life goals, form relationships, and shape their personal and professional identities to achieve fulfillment.\nCoordinate individual and group-level efforts on a collaborative team. Gather and leverage the perspectives of external partners. Select project directions strategically by aligning analytic opportunities with public interest.\nCourse Format:\nThe course curriculum is broken into three parts, moving through the increasingly sophisticated things we can do with data: Information, Measurement, and Discovery.\nThe course will meet weekly remotely through Zoom.\nIt is encouraged that all students attend Zoom meetings. Though you will not be graded on attendance.\nWe will learn R, an open source statistical programming language.\nThe typical class meeting will be split into four parts:\nA short lecture on R or related data principles\nChecking in with students on challenges they are facing with R\nWorking through examples with students.\n\nThe R component of the course takes the form of a flipped classroom, meaning that students are expected to do their technical readings and exercises in advance of class. We will use the class time as a workshop to review these skills.\nData Collaborations:\nWe will learn how to use R to visualize, manipulate, and analyze naturally-occurring data by working with data sets from BARI’s COVID in Boston database which draws from numerous administrative and internet sources. Each student will be assigned to a collaborative team that will analyze one of these data sets. Teams will be constructed using the preferences expressed by students in the pre-semester survey.\nThe data collaborations will be the basis of weekly assignments and semester projects. All such assignments will be completed by individuals, but students are encouraged to share documents and modified data with each other. Teams will also work together to combine their advances with the data into data products. Major assignments and data products will be shared back with our municipal partners.\nData will be made available to students via BARI’s Boston Data Portal, hosted by Dataverse. You will need to create a Dataverse account. See instructions for using Dataverse on Canvas under Course Material - > Technical Support Documents.\nAssignments\nEach week will entail: readings with reading responses; and R-based data explorations. Each unit will also include one city exploration assignment, one midterm (or, for the third unit, the final project), and one service-learning reflection.\nReading Responses\nReadings are listed in the syllabus and will be posted on Canvas unless otherwise specified.\nEach reading assignment will be accompanied by a short reading prompt meant to guide reading.\nStudents will turn in their response to the reading prompt, which must be at least 250 words, on the Canvas discussion board designated for that week by Thursday at noon.\nStudents will be expected to browse each other’s responses as well. It will be required to respond to at least one other student’s response by Saturday\n\nPosts based on the reading prompt are graded out of 2 points: 2 = complete, 1 = incomplete (under word count / not entirely relevant to the reading / limited original thought), 0 = not turned in. Instructor will award partial points as appropriate.\nResponses to other students will be graded out of 1 point: 1 = complete, 0 = insufficient. There will be no partial credit. These responses do not have a length requirement, but need to comment substantively on the classmate’s original post. (For example, “This is a cool idea!” would not be sufficient, but “I really enjoyed the way you framed sensor systems in terms of their ethical challenges,” would be.)\nR-based Data Exploration\nR-based data explorations will ask students to practice the skills learned that week in R to analyze their data set. They will be described in detail during each week’s in-class workshop and posted on Canvas the week they are assigned.\nR-based data explorations will revolve around the data set that you have elected to focus on for the semester. Though students will work in collaborative groups everyone must turn in their own, independent work. Nonetheless, students are encouraged to collaborate with other group members and classmates in all work. These assignments are intended to build towards the midterm and final projects.\nThe write-up should address: Background, or why is this interesting?; Analysis, or what you found out?; and Interpretation, or what does this mean? It should be completed in an Rmarkdown document (.Rmd) that intermingles code and prose.\nR-based data explorations will be submitted twice, first as a Draft and then as a Final product. The drafts are due by Wednesday and the Final submission is due on Sunday at 23:59. They will be submitted on Canvas.\nR-based data explorations will be graded on syntax style according to style.tidyverse.org ch. 1 and 2.\nCity Exploration Assignments\nThere will be one city exploration assignment during each unit of the course in which students will visit a part of the city to which they have never (or rarely) been, either in person or virtually. Each walk will have a different theme, connecting the data curriculum of that unit to the real-world context of the municipality whose data you are analyzing. Guidance on whether to visit places in-person or virtually will be contingent on current circumstances and all city explorations will offer online resources for a virtual option.\nFor each city exploration assignment, students will complete a 4-5 pg. walk memo. Each walk memo must also include at least two pictures or screen shots from the exploration (not counted towards length). \nRubric for city exploration assignments included on the course website and Canvas where assignments are announced.\nService-Learning Reflections\nAt three points during the semester (see schedule), each student will write a 2-3 pg. (double- spaced) memo on: how their work in the course has been influenced by the perspectives of external partners and by exposure to real-world contexts; how those experiences have helped them to better understand the material and their data; and the ways in which the partnership has revealed the real-world utility of the skills. Students are also welcome to explore the limitations of these themes, or ways in which they would like to see them continue to grow.\nGiven that we will not be working direct external partners this semester and the challenges that remote learning face, please comment on how your analyses could be applied to existing social issues.\n\nService-learning reflections are graded out of 2 points: 2 = complete, 1 = incomplete (short / not fully engaging the question), 0 = not turned in. Instructor will award partial points as appropriate.\nMidterms and Finals\nEach section of the course will conclude with a major project. These are:\nInformation: README Documentation will provide a short series of facts derived from the data set that anyone working with the data might find informative. It will include code for replicating the analyses underlying these facts so that the report might be updated regularly or for subsets of the data.\nMeasurement: Original Measurement will describe a novel set of measures that have been derived from your data set, code that can replicate their construction, and a description of their distribution across the city.\nDiscovery: Inform, Measure, and Discover will combine the work from the two midterms with original analyses that utilize the measures and insights you have developed across the semester.\nAt each of these junctures collaborative teams will work together to organize and document the additions and modifications they have made to their data set, creating a single data product they will upload to the Boston Data Library.\nRubrics are posted with the fuller assignment descriptions on Canvas.\nGrading\n20% Reading Responses and Other Small Assignments. Responses will be considered your participation grade.\n10% Walk Memos\n15% Week-to-Week R Assignments\n15% Information Mid-Term Project: README Document\n15% Measurement Mid-Term Project: Original Measurement\n25% Final Project (Paper and Presentation)\nAcademic Honesty:\nStudents are expected to abide by Northeastern University’s Academic Integrity Policy, which you can read at: http://www.northeastern.edu/osccr/academicintegrity/\nIncompletes:\nThe grade incomplete (INC) is granted only where a student is approved to make up a single key requirement of the course, such as one of the major assignments.\nOther Expectations:\nLate assignments will be discounted 10% per day. After a week, they will no longer be accepted. If an assignment was to be posted online in advance of class to stimulate discussion there will be no opportunity for late credit.\nE-mailed assignments, except in the case of an absence, will be considered 1 day late.\nLate assignments or absences will only be considered excused in the case of a doctors note or evidence of an academic conflict.\nPlease contact me at j.parry@northeastern.edu if you think you’ll be late on an assignment or have other concerns.\n\n\n\n",
      "last_modified": "2021-01-25T07:38:46-05:00"
    },
    {
      "path": "week-0.html",
      "title": "Welcome!",
      "author": [],
      "contents": "\nHello and welcome to Big Data for Cities! This course is intended to introduce you to the field of urban informatics. Throughout this course we will expound upon the intersection of big data and the city with an emphasis on the importance of administrative data.\nIn recent years the city has seen a vast proliferation of data whether it be from cell phone records to social media posts, calls for government services, or to digitized historical records. These new resources present a clear opportunity for research, policy, and practice. Gleaning insights from these data require the use of modern statistical software, a nontrivial task! A further challenge is the rigorous standards needed to interpret the data collected. These skills form the foundation of the emerging field of urban informatics and therefore the main learning objectives of this course.\nThroughout this course we will use the Statistical Programming Language R for all of our data related tasks. Throughout this course we will utilize the books R for Everyone, R for Data Science, and The Urban Informatics Toolkit (UITK).\nTo prepare for the course, I would strongly suggest you read the below suggested readings. Additionally, please ensure you do your course preparation listed below prior to next week. All in all, it should take you about 30 minutes. 😊\nReadings\nUtility and Danger of Big Data\nData in the Municipal Context\nSchools of Urban Informatics\nCourse Preparation\nRead UITK Ch. 2: This chapter will introduce you to R, and the RStudio IDE.\nInstall R\nInstall RStudio\nPre-course survey\n\n\n\n",
      "last_modified": "2021-01-25T07:38:49-05:00"
    },
    {
      "path": "week-1.html",
      "title": "Week 1 - Telling a Data Story",
      "author": [],
      "contents": "\nOverview\nMost data come to us as a set of rows (or cases) with values for a set of columns (or variables). But their composite is so much more than that. Each row provides us with a detailed description of a case, be it an object or event, and the variables provide an opportunity to compare across these cases. This enables us not only to translate the information contained in any given row into a data story but also a more general understanding of the knowledge contained in the data themselves.\nIn this module, you will use basic R functions to expose details of a data frame, particularly the content of individual cases, and use that information to describe the contents of a data set.\nTo complement our introduction to R, we will explore the fundamental themes of urban informatics by discussing an initial set of readings on 311 systems and New York City’s Mayor’s Office of Data Analytics.\nLearning objectives\nRun R scripts in RStudio to interact with data objects\nUse basic R commands to expose and interpret details of a data frame for individual case\nUtilize R’s technical documentation to explore new functions\nConsider the implications of how a data record is generated\nDescribe the five fundamental themes of the field of Urban Informatics\nSubstantive Readings\nIs the Cost of 311 Systems Worth the Price of - Knowing?\nWhat a Hundred Million Calls to 311 Reveal about New - York\nHow Public Data Can Improve Services and Empower - Communities\nNYC’s Mayor’s Office of Data Analytics\nTechnical Readings\nTidyverse style guide chapters 1 and 2\nUITK:\nR as a calculator\nReading Data\nExploratory Visual Analysis\nGeneral Data Manipulation\n\nLander: Chapters 1, 2, 4, 5.1, 6\nData Assignment\nFor this week’s data assignment, briefly describe the structure of either your whole data set or of some meaningful subset (number of rows, columns, names of relevant variables).\nDescribe at least three cases (rows) from this set/subset using the information contained in the variables you see as relevant.\nWhat have you learned from these cases individually, and from the differences between them?\nHow do they illustrate what we can learn from these data more generally?\nCan you infer things about the cases that are not explicitly in the data?\n\n\n\n",
      "last_modified": "2021-01-25T07:40:17-05:00"
    },
    {
      "path": "week-10.html",
      "title": "Week 10 - Modeling the City",
      "author": [],
      "contents": "\nOverview\nThis module picks up right where the last module left off, extending our toolbox for inferential statistics with two tests that compare differences across groups—the t-test and ANOVA—and using these to examine whether custodianship differs across different types of neighborhoods.\nYou will also utilize these two tools to further analyze the distribution of your own measures across Boston.\nWe will examine how projects in New York and Chicago are using statistics to model the city as a “math equation.”\nLearning Objectives\nCompare differences in one or more variables between two groups with t-tests\nCompare differences in one or more variables between three or more groups\nRepresent differences between groups in ggplot2\nArticulate the opportunities and limits for inferential statistics in the study of the city\nSubstantive Readings\nLife in the City is Essentially One Giant Math Problem by Jerry Alder, Smithsonian Magazine\nHudson Yards: The First Quantified Community\nUniversity of Chicago to Serve as Test Bed for Array of Things\nCenter for Urban Science and Progress\nUrban Center for Computation and Data\nPrompt\n“How are the Chicago and New York approaches to urban big data similar? How are they different? Do you prefer one style over the other? If so, why or why not?”\nTechnical Readings\nLander: Chapter 15.3\nData Assignment\nRun at least one t-test and one ANOVA utilizing your data and describe the results. The two (or more) analyses should inform each other in some way.\nInclude at least one figure representing the relationship(s).\n\n\n\n",
      "last_modified": "2021-01-25T07:38:52-05:00"
    },
    {
      "path": "week-11.html",
      "title": "Week 11 - Networks and the City",
      "author": [],
      "contents": "\nOverview\nOver the course of the semester we have developed a variety of data science skills and a considerable familiarity with building permits and their implications across the greater Boston region. This module there is a pressing job to do. This week, we are going to capitalize on the expertise we have developed with municipal administrative records to respond to a challenge posed by a visiting public sector partner. Much like real-world jobs in urban informatics, we will have a limited amount of time to generate a set of actionable insights and recommendations.\nLearning Objectives\nRespond to a time-sensitive request for a targeted analysis\nSkill: Identify how the data to which you have access can help inform the concern at hand\nSkill: Execute and communicate the results of your analysis\n\nDescribe the potential of network science for the study of the city\nSkill: Define the role of “nodes” and “links” in the structure of a network\nSkill: Identify the various classes of question that a network science approach might answer\n\nSubstantive Readings\nSun et al. 2015 Quantifying long-term evolution of intra-urban spatial interaction\nThe Future Cities Lab\nPrompt\n“Sun et al. used network data—that is, the analysis of interconnections between individuals—to study the city. What did they learn? Do you see further promise in an urban network science?”\n\n\n\n",
      "last_modified": "2021-01-25T07:38:54-05:00"
    },
    {
      "path": "week-12.html",
      "title": "Week 12 - The Future of Urban Informatics",
      "author": [],
      "contents": "\nOverview\nWe have nearly reached the end of the semester and it is about time to bring all the hard work we have done to a final set of products. Between this week and next we will bring our efforts to their conclusion. This week we will complete our final city exploration–an in-person urban hike–and we will conduct workshops to brainstorm about the Final Paper, Presentation, and Database, which will be due at the end of next week.\nIn parallel, we will read Anthony Townsend’s summary of “The New Urban Science” and the programs that are pursuing it. The article will serve as a jumping off point so that we can discuss our own thoughts on the overall nature of the field is and what the future holds for it.\nLearning Objectives\nCharacterize the field of urban informatics and its future\nSkill: Describe the organization of the field of urban informatics in terms of its themes and - programs\nSkill: Identify the themes that you think are facing the field of urban informatics\n\nSubmit 3rd City Exploration: Urban Hike assignment.\nSubstantive Readings\nOne Last Reading…\nTownsend 2015 Making sense of the new urban science\n…And a Few Websites\nData for Black Lives\nDetroit Community Technology Project\nVital Village\nMetroLab Network’s Innovation of the Month\nPrompt\nDo you agree or disagree with Townsend’s assessment of the field? How so?\nHow do these newer efforts reinforce or shift the focus of the field?\n\n\n\n",
      "last_modified": "2021-01-25T07:38:55-05:00"
    },
    {
      "path": "week-2.html",
      "title": "Week 2 - Pulse of The City",
      "author": [],
      "contents": "\nSubstantive Readings\n“Towards a comparative science of cities: Using mobile traffic records in New York, London, and Hong Kong.” by Grauwin et al.\nSenseable Cities at MIT\nPrompt\nWhat did Senseable learn about the patterns (or pulse) of the city through cell phone data?\nHow might the interpretations differ depending on who does and does not own or regularly use cell phones?\nHow does Senseable’s work more broadly build upon the themes of urban informatics we discussed surrounding 311?\nTechnical Readings\nLander: Chapters 3, 7, 15.1\nTidy Data, Wickham\nUITK:\nThat’s too much data\nThe %>%\n\nData Assignment\nFor this week’s data assignment, briefly describe the structure of either your whole data set or of some meaningful subset (number of rows, columns, names of relevant variables).\nGenerate at least three interesting pieces of information or patterns from your data set and describe the insights they provide regarding the dynamics of the city. These can be communicated as numbers, graphs, or both and should convey what you see as the overarching information contained in the data set.\nFind at least two things in your data set that are strange, not make sense, or are contrary to your expectations.\n\n\n\n",
      "last_modified": "2021-01-25T07:38:57-05:00"
    },
    {
      "path": "week-3.html",
      "title": "Week 3 - Revealing Knowledge",
      "author": [],
      "contents": "\nOverview\nDigital data are rich in content and detail, but they do not automatically become knowledge. It is up to the analyst to revise variables or to create new ones that makes this knowledge more accessible, that it might be leveraged for research, policy or practice. In this module, you will create new or revised variables in your own data set that facilitate subsequent analysis. This might include “fixing” or omitting erroneous cases, reorganizing to make an existing variable more tractable, or combining information from multiple variables to make critical information more directly accessible. We will also look at the world of “Smart Cities,” where private corporations like Google Sidewalk Labs have promised to leverage data to create technologies and programs that make urban systems more efficient and responsive—as well as some critics who make clear that making cities smart is about more than just data. Finally, this week will feature the first City Exploration assignment in which you will virtually visit a neighborhood of your choice in order to determine whether the patterns that you are seeing in your data set mean what you think they do about what is actually going on in a neighborhood.\nLearning objectives\nLearning objectives for this module are to:\nPlanning out the preparation of data for analysis by cleaning and creating more useful variables.\nCreate new variables that modify an existing numeric variable or are combinations of multiple numeric variables.\nCreate new variables based on existing string (i.e., character) variables.\nCreate and manipulate date variables with package lubridate.\nVisualize the relationships between multiple variables.\nEvaluate the private corporation approach to “smart cities”\nEvaluate the validity of naturally-occurring data with real-world events and conditions.\nSubstantive Readings\nLinkNYC\nSidewalk Labs\nSidewalk Toronto\n“Smart City Playbook” by the Mayor’s Office of Urban Mechanics in Boston\n“Google’s Guinea-Pig City” by Molly Sauter, The Atlantic\nPrompt\nHow would you describe the ‘smart cities’ approach to urban big data and its critiques?\nWhat is your opinion of how data is being used and interpreted in this context?\nTechnical Readings\nLander: Chapters 9, 11.1\nCreating New Measures\nGrammar of layered graphics\nVisualizing Trends and Relationships I\nVisualizing Trends and Relationships II\nData Assignment\nCreate at least three new variables, each of which must either;\nmake some angle of your data’s content more interpretable,\nfix some issue in the data.\nPlease make sure to explain why these variables are useful.\n\nDescribe the contents of these variables using analysis and visualization.\nLooking forward\nFirst city walk due next week.\n\n\n\n",
      "last_modified": "2021-01-25T07:38:59-05:00"
    },
    {
      "path": "week-4.html",
      "title": "Week 4 - Two dueling perspectives",
      "author": [],
      "contents": "\nOverview\nThe great Sherlock Holmes once said, “It is a capital mistake to theorize before one has data.” On the other hand, an old saying among scientists is that “There can be no data without theory,” because one cannot generate information without first asking questions. This symbiosis between theory and data has been critical to the work we have done thus far. As we have seen, extracting information from a data set requires knowing what we want to learn and making a number of decisions to reveal it through analyses and visualizations, and those analyses and visualizations then stimulate new questions. As we spend this week preparing for the midterm, we will be considering this question of what we can learn from our data set, and how we want to go about exposing it and communicating it through a Read-Me Document. In addition, we will read two essays about whether data “speak for themselves,” or if there is still a need for theory in guiding data science.\nLearning objectives\nAssess the role of theory in data science.\nDistinguish between data- and theory-driven approaches.\nSubstantive Readings\n“The End of Theory: The Data Deluge Makes the Scientific Method Obsolete,” by Chris Anderson, Wired.\n“The End of Theory in Science?” by Massimo Pigliucci, EMBO Reports.\nPrompt\nWhat’s your take on Anderson and Pigliucci’s debate about the role of theory in data science?\nAssignment\nFirst City Walk due Friday 23:59.\nLooking forward\nFirst midterm due next Friday!\n\n\n\n",
      "last_modified": "2021-01-25T07:39:00-05:00"
    },
    {
      "path": "week-5.html",
      "title": "Week 5 - Measurment / Latent Constructs",
      "author": [],
      "contents": "\nOverview\nA major criticism of big data and other “naturally occurring” records is that they have lots of information, but do they include the things we need and want to know? Put another way, what are they capable of measuring about people, places, and things? In this module, you will answer this question using two tools. The first is a schema, which allows us to understand how records connect to other data sets based on the very people, places, and things we want to know more about. The second is an approach to measurement that organizes the world into latent constructs, or underlying characteristics that we believe exist, and manifest variables, or measurable elements that reflect latent constructs. Through this lens, we can build measures that describe the features of those people, places, and things. We see this approach illustrated in a chapter about the work that my own organization, the Boston Area Research Initiative, has done to translate administrative data into a series of ecometrics that describe the social and physical characteristics of the neighborhoods of Boston.\nLearning objectives\nDescribe the schema associated with a dataset.\nPropose aggregate measures from naturally-occurring data that are rooted in concepts of interest.\nSubset a data frame based on the contents of another data frame.\nConsider the implications of the data-generation process for the interpretation of aggregate variables.\nSubstantive Readings\nO’Brien 2018 The Urban Commons Chapter 2: Through pg. 65 and 85-90 required; summary sections for the rest of the chapter will suffice.\nBoston Area Research Initiative\nPrompt\nWhat is the ‘ecometric’ approach to big data and how does it solve the problem of ‘measurement’ in urban big data?\nHow does it fit in with BARI’s broader vision?\nData Assignment\nFor this week’s data assignment, propose at least one latent construct that you would like to measure with your data set and the geographic level at which you would want to measure it.\nIn addition, describe how this construct is interesting and at least one manifest variable for measuring it. Use the latent construct modeling notation from this week’s lesson presentation to bring it across.\nNote: Your manifest variable can be an idea at this point and we can figure out how to code it in R in the coming weeks.\nAssignment\nMidterm 1 - README due Friday 23:59.\nLooking forward\nFirst service learning response due next Friday.\n\n\n\n",
      "last_modified": "2021-01-25T07:39:02-05:00"
    },
    {
      "path": "week-6.html",
      "title": "Week 6 - Linking Data",
      "author": [],
      "contents": "\nOverview\nData come from many different sources—in this class alone you all are working with multiple data sets that describe distinct aspects of the city. Part of the opportunity of “big data” is the potential to coordinate these data sets in order to analyze them in conjunction with each other. In order to do so, however, we must leverage the schemas we learned about in the last module—that is, the people, places, and things that they share in common—to link them. In this module, you will leverage the geographical infrastructure of Boston to develop aggregate measures describing some unit of analysis (e.g., streets, census tracts), and then link them with other information describing those same units. We will also learn about the Actionable Intelligence for Social Policy’s efforts to solve this same problem for linking information about individuals across the data generated by the many different agencies responsible for health and human services.\nLearning objectives\nCalculate measures at aggregate levels from records\nLink data from different sources using shared units of analysis in a schema\nVisualize two variables together in a dot plot in ggplot2\nEvaluate the validity of measures\nEvaluate the trade-offs surrounding data analysis and privacy\nSubstantive Readings\nChoose one of the two papers:\nCulhane et al. (2007). “Testing a typology of family homelessness based on patterns of public shelter utilization in four U.S. jurisdictions”\nBowden et al. (2020). “Case identification of mental health and related problems in children and young people using the New Zealand Integrated Data Infrastructure.”\nAnd peruse Actionable Intelligence for Social Policy.\nPrompt\nIDSes merge a wealth of personal data to support comprehensive scholarly and policy analysis.\nTry to draw a diagram of the schema that you think enabled the study that you read. What other research questions do you think that that the data in that schema might be able to answer?\nTechnical Readings\nLander: Chapters 11.2, 12.1\nUITK:\nSummary Statistics\nSummarizing the tidy way\n\nR4DS - Grouped summarise with summarise()\nData Assignment\nBe sure to describe why the construct is interesting and how the specific calculations you are using capture it.\nAs you analyze the content of these new variables, be sure to include at least one dot plot that shows the relationships between two variables at the aggregate level.\nAssignment - Service Learning Response\nNow that you’ve completed your midterm, how did the city walk and in-class workshop influence the practical application of your analysis in working with the data? Going forward, what are your goals in this aspect (practical application-wise)?\nDue Friday at 23:59.\n\n\n\n",
      "last_modified": "2021-01-25T07:39:05-05:00"
    },
    {
      "path": "week-7.html",
      "title": "Week 7 - Mapping the City",
      "author": [],
      "contents": "\nOverview\nData describing the city are special because they all reference the same set of buildings, streets, and neighborhoods. As we saw last week, this enables us to easily link measures that describe the same units. It also means that these data are spatial, and can be communicated and examined through maps. In this module, you will create maps that illustrate the distribution of one or more measures across the urban landscape. We will also learn about the Bartlett Centre for Advanced Spatial Analysis at University College London, one of the original urban informatics research centers, and their efforts to map the city.\nLearning objectives\nDescribe the differences between spatial data and traditional tabular data\nUtilize spatial data files in R.\nCreate chloropleths that map the distribution of a metric across the city using ggplot2 and ggmap\nProcess and visualize spatial data in R in a variety of additional ways.\nTrace the origins of spatial analysis in urban informatics.\nConnect the content of administrative data with real-world events and conditions.\nSubstantive Readings\nRogers (2013). “John Snow’s data journalism: the cholera map that changed the world.”\nPalominos & Smith (2020). “Identifying and Characterising Active Travel Corridors for London in Response to COVID-19 Using Shortest Path and Streetspace Analysis.”\nThe Bartlett Centre for Advanced Spatial Analysis\nTechnical Readings\nUITK - Spatial Analysis\nData Assignment\nContinue working on the development of your latent constructs and any related unit-level variables.\nCreate a map of at least one of these variables.\nMake sure to use the map as a way to reveal the distribution of this variable across the city and to further our understanding of the urban landscape.\nLooking forward\nSecond city walk due next Friday.\n\n\n\n",
      "last_modified": "2021-01-25T07:39:07-05:00"
    },
    {
      "path": "week-8.html",
      "title": "Week 8 - Provocations for Big Data",
      "author": [],
      "contents": "\nOverview\nAs we conclude Unit 2 it is time again to reflect a bit on our use of administrative data. First, as with last semester, we will use workshops to ensure that the measures that we are building are in fact interesting, meaningful, and potentially useful for research, policy, and practice. This will culminate in the completion of the second midterm, which will report these measures and their content. We will also read Danah Boyd and Kate Crawford’s “Six Provocations for Big Data,” which further forces us to consider the philosophical and ethical challenges that accompany this work.\nLearning objectives\nAssess the philosophical challenges of working with modern digital data\nSubstantive Readings\nBoyd & Crawford 2011 Six provocations for big data\nPrompt\nHow do you find Boyd & Crawford’s ‘provocations’ useful for the field of urban informatics?\nAre there particular issues that you think this field does particularly well with and others where it needs to mature?\nAssignment\nSecond City Walk due Friday 23:59.\nLooking forward\nMidterm 2 due next Friday.\n\n\n\n",
      "last_modified": "2021-01-25T07:39:09-05:00"
    },
    {
      "path": "week-9.html",
      "title": "Week 9 - Beyond Measurement",
      "author": [],
      "contents": "\nOverview\nThe third and final unit of the course will take us beyond measurement to “discovery”—how can we use the tools of statistics to better understand the dynamics of the urban landscape? This week we will begin with an overview of inferential statistics and the introduction of correlation and regression.\nIn this module, you will utilize correlation and regression to analyze the relationship of two or more measures across Boston.\nWe will also take a look at the Santa Fe’s Institute’s use of correlation and regression to develop universal models of urban scaling.\nLearning Objectives\nDescribe the premises of inferential statistics\nConduct correlations to describe the strength of relationship between two variables\nConduct regressions to predict one variable’s distribution in terms of two or more independent - variables\nRepresent the linear relationships between variables\nEvaluate the implications of a universal scaling law for cities\nSubstantive Readings\nBettencourt et al 2010 Urban scaling and its deviations Revealing the structure of wealth, innovation and crime across cities\nSanta Fe Institute’s Program on Cities, Scaling, and Sustainability\nPrompt\n“What is it that Bettencourt et al. claim to have discovered? How do you interpret that?”\nTechnical Readings\nLander: Chapter 15.2\nUITK - Statistics\nData Assignment\nRun at least one correlation and one regression on your data, and describe the results. The two (or more) analyses should inform each other in some way (e.g., the regression further tests the correlation).\nInclude at least one figure representing the relationship(s).\nAssignment\nMidterm 2 due Friday 23:59.\nLooking forward\nSecond service learning reflection due next Friday.\n\n\n\n",
      "last_modified": "2021-01-25T07:39:10-05:00"
    },
    {
      "path": "your-instructor.html",
      "title": "About the instructor",
      "author": [],
      "contents": "\nHey, everyone! I am extremely excited to be teaching this course this semester. I suspect you may be wondering who I am. Let me try and dispel that a little bit.\nAs you’ve hopefully noticed by now, my name is Josiah Parry. Please do not call me “Professor,” I’ll kindly ask you to call me by my first name. I am a graduate of the Urban Informatics program here at Northeastern. I’ve gone through this curriculum myself!\nBack in September, inspired by the pandemic, I left the comfort of Central Square apartment to move to Portland, ME for a change. I will say that I miss Felipe’s, I miss Pavement coffee, and I miss wandering around Harvard Square and occasionally losing in chess games to Doc and buying him a Spanish latte. But Portland brings it’s own charisma and charm. It is quieter. It is has arguably tastier food and more quality espresso per square mile.\nIn my new apartment overlooking Portland’s West End you’ll find me working remotely for RStudio, PBC. That looks like a whole lot of zoom calls, emailing, and R programming. I am on the Customer Success team at RStudio working with our public sector customers. I get to discuss all things R, data, and infrastructure with government agencies around the world whether they be municipalities, state, or federal organizations.\nOn the weekends you can probably find me at Sunday River enjoying what little snow there may be. I know no other way to make it through the harshness of a New England winter!\nPlease email me if you have any questions :)\n\n\n\n",
      "last_modified": "2021-01-25T07:39:11-05:00"
    }
  ],
  "collections": []
}
